{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 15 (1834914018.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 21\u001b[1;36m\u001b[0m\n\u001b[1;33m    if not 'titles' in locals():\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'if' statement on line 15\n"
     ]
    }
   ],
   "source": [
    "# USER-SPECIFIC: The folder paths holding simulation outputs and observations\n",
    "\n",
    "if not 'Simulation_output_folders' in locals():  \n",
    "    \"\"\"\n",
    "    Simulation_output_folders = [\n",
    "        r'/Users/admin/Desktop/OneDrive - IIASA/Papers/2024_Refining_humans_CWatM/Results/output_5min_Bhima_1979_2016',\n",
    "        #r'/Users/admin/Desktop/OneDrive - IIASA/Papers/2024_Refining_humans_CWatM/Results/output_5min_Bhima_1979_2016',\n",
    "        #r'/Users/admin/Desktop/OneDrive - IIASA/Papers/2024_Refining_humans_CWatM/Results/Bhima_01011979_31122016_StdReservoirs2',\n",
    "        r'/Users/admin/Desktop/OneDrive - IIASA/Papers/2024_Refining_humans_CWatM/Results/Bhima_01011979_31122016',    \n",
    "    ]\n",
    "    \"\"\"\n",
    "    #Simulation_output_folders = [r'/Users/admin/Desktop/ETH/Discharge_comparison']\n",
    "    Simulation_output_folders = [] #[r'C:\\Users\\Smilovic\\OneDrive - ETH Zurich\\Desktop\\Discharge_comparison']\n",
    "\n",
    "if not 'Simulated_stations_Excel_folders' in locals():\n",
    "    #Simulated_stations_Excel_folders = []\n",
    "    #Simulated_stations_Excel_folders = [r'C:\\Users\\Smilovic\\OneDrive - ETH Zurich\\Desktop\\Discharge_comparison\\TOPWATCH outputs\\zambezi_w5e5_v002_Itezhitezhi\\cells',\n",
    "    #                                   r'C:\\Users\\Smilovic\\OneDrive - ETH Zurich\\Desktop\\Discharge_comparison\\PCRGLOBWB outputs'\n",
    "    #                                   ]\n",
    "\n",
    "if not 'titles' in locals():\n",
    "    titles = ['dataset '+str(num) for num in range(len(Simulation_output_folders)+len(Simulated_stations_Excel_folders)+1)]\n",
    "if not 'output_variable' in locals():\n",
    "    output_netcdf = 'discharge_daily'\n",
    "    output_netcdf = 'pcrglobwb_dynqual_cmip6-isimip3-w5e5_historical-reference_discharge_zambezi_daily_1980_2019_basetier1'\n",
    "    output_variable = 'discharge'\n",
    "    \n",
    "# observations_folder holds one Excel (observation_locations.xlsx) with names and locations, and\n",
    "    # a folder (Observations) with an Excel file for each station. The Excel files are named after the station names.\n",
    "    #\n",
    "    # observations_locations.xlsx has three columns: Station, Latitude, Longitude\n",
    "    #\n",
    "    # observations_folder\n",
    "    # ↵ observations_locations.xlsx\n",
    "    # ↵ Observations\n",
    "    #   ↵ StationName1.xlsx #first two rows not read\n",
    "    #   ↵ StationName2.xlsx #first two rows not read\n",
    "    #   ↵ ...\n",
    "if not 'template' in locals():\n",
    "     template = \"plotly_dark\"\n",
    "     \n",
    "if not 'observations_folder' in locals():      \n",
    "    #observations_folder = r'/Users/admin/Documents/GitHub/WAT-Tools/Examples/example_Compare_at_stations_with NetCDF/Observations_otta'\n",
    "    #observations_folder = r'/Users/admin/Desktop/ETH/Discharge_comparison/Zambezi_observations'\n",
    "    observations_folder = r'C:\\Users\\Smilovic\\OneDrive - ETH Zurich\\Desktop\\Discharge_comparison\\Zambezi_observations'\n",
    "\n",
    "if not 'Excel_two_first_rows_not_read' in locals(): \n",
    "    Excel_two_first_rows_not_read = False\n",
    "\n",
    "if not 'search' in locals(): \n",
    "    search = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset, num2date\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_discharge_folder = os.path.join(observations_folder, 'Observations')\n",
    "Simulated_output_paths = [folder + '/' + output_netcdf + '.nc' for folder in Simulation_output_folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def geo_idx(dd, dd_array):\n",
    "    \"\"\"\n",
    "     search for nearest decimal degree in an array of decimal degrees and return the index.\n",
    "     np.argmin returns the indices of minium value along an axis.\n",
    "     so subtract dd from all values in dd_array, take absolute value and find index of minium.\n",
    "    \"\"\"\n",
    "    \n",
    "    geo_idx = (np.abs(dd_array - dd)).argmin()\n",
    "    \n",
    "    return geo_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "### Observed discharge from Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated discharge from NetCDF4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from functions import read_observations_excel\n",
    "Stations_namesLocations, DATES_observed, FLOWS_observed = read_observations_excel(observations_folder=observations_folder)\n",
    "\n",
    "\n",
    "NC_SIMULATED = []\n",
    "LATS = []\n",
    "LONS = []\n",
    "DATES_SIMULATED = []\n",
    "OUTPUTS_SIMULATED = []\n",
    "\n",
    "\n",
    "print('Loading simulations')\n",
    "\n",
    "latlon_coord = True\n",
    "for simulation in Simulated_output_paths:\n",
    "    \n",
    "    nc_simulated = Dataset(simulation, 'r')\n",
    "    try:\n",
    "        lats = nc_simulated.variables['lat'][:]\n",
    "        lons = nc_simulated.variables['lon'][:]\n",
    "    except:\n",
    "        latlon_coord = False\n",
    "        lats = nc_simulated.variables['x'][:]\n",
    "        lons = nc_simulated.variables['y'][:]\n",
    "        \n",
    "    Dates_simulated = num2date(nc_simulated.variables['time'][:], units=nc_simulated.variables['time'].units, \n",
    "                               only_use_cftime_datetimes=False, only_use_python_datetimes=True)\n",
    "\n",
    "    #netcdf had incorrect dates, so the following fix:\n",
    "    #Dates_simulated = num2date([29220+n for n in range(14244)], units=nc_simulated.variables['time'].units, \n",
    "    #                           only_use_cftime_datetimes=False, only_use_python_datetimes=True)\n",
    "\n",
    "    #print(nc_simulated.variables['time'][:])\n",
    "    #print(Dates_simulated)\n",
    "    #print(nc_simulated.variables['time'].units)\n",
    "    \n",
    "    Dates_simulated = pd.to_datetime(Dates_simulated).date\n",
    "\n",
    "    Outputs_simulated = []\n",
    "    \n",
    "    NC_SIMULATED.append(nc_simulated)\n",
    "    LATS.append(lats)\n",
    "    LONS.append(lons)\n",
    "    DATES_SIMULATED.append(Dates_simulated)\n",
    "    OUTPUTS_SIMULATED.append(Outputs_simulated)\n",
    "titles_search = []\n",
    "for discharge_location in Stations_namesLocations:\n",
    "    in_lat = discharge_location[1]\n",
    "    in_lon = discharge_location[2]\n",
    "    #print(in_lat, in_lon)\n",
    "    \n",
    "    for sim in range(len(Simulated_output_paths)):\n",
    "        lats = LATS[sim]\n",
    "        lons = LONS[sim]\n",
    "    \n",
    "        lat_idx = geo_idx(in_lat, lats)\n",
    "        lon_idx = geo_idx(in_lon, lons)\n",
    "        #print(lats[lat_idx], lons[lon_idx])\n",
    "\n",
    "        if latlon_coord:\n",
    "\n",
    "            OUTPUTS_SIMULATED[sim].append(NC_SIMULATED[sim].variables[output_variable][:, lat_idx, lon_idx])\n",
    "            \n",
    "            if search:\n",
    "                OUTPUTS_SIMULATED[sim].append(NC_SIMULATED[sim].variables[output_variable][:, lat_idx-1, lon_idx-1])\n",
    "                OUTPUTS_SIMULATED[sim].append(NC_SIMULATED[sim].variables[output_variable][:, lat_idx-1, lon_idx])\n",
    "                OUTPUTS_SIMULATED[sim].append(NC_SIMULATED[sim].variables[output_variable][:, lat_idx-1, lon_idx+1])\n",
    "                OUTPUTS_SIMULATED[sim].append(NC_SIMULATED[sim].variables[output_variable][:, lat_idx, lon_idx-1])\n",
    "                OUTPUTS_SIMULATED[sim].append(NC_SIMULATED[sim].variables[output_variable][:, lat_idx, lon_idx+1])\n",
    "                OUTPUTS_SIMULATED[sim].append(NC_SIMULATED[sim].variables[output_variable][:, lat_idx+1, lon_idx-1])\n",
    "                OUTPUTS_SIMULATED[sim].append(NC_SIMULATED[sim].variables[output_variable][:, lat_idx+1, lon_idx])\n",
    "                OUTPUTS_SIMULATED[sim].append(NC_SIMULATED[sim].variables[output_variable][:, lat_idx+1, lon_idx+1]) \n",
    "\n",
    "                \n",
    "                titles_search.append([\n",
    "                    str([LATS[sim][lat_idx-1], LONS[sim][lon_idx-1]]),\n",
    "                    str([LATS[sim][lat_idx-1], LONS[sim][lon_idx]]),\n",
    "                    str([LATS[sim][lat_idx-1], LONS[sim][lon_idx+1]]), \n",
    "                    str([LATS[sim][lat_idx], LONS[sim][lon_idx-1]]),\n",
    "                    str([LATS[sim][lat_idx], LONS[sim][lon_idx+1]]), \n",
    "                    str([LATS[sim][lat_idx+1], LONS[sim][lon_idx-1]]),\n",
    "                    str([LATS[sim][lat_idx+1], LONS[sim][lon_idx]]), \n",
    "                    str([LATS[sim][lat_idx+1], LONS[sim][lon_idx+1]])])\n",
    "            \n",
    "        else:\n",
    "            OUTPUTS_SIMULATED[sim].append(NC_SIMULATED[sim].variables[output_variable][:, lon_idx, lat_idx])\n",
    "            \n",
    "\n",
    "from functions import read_simulations_excel\n",
    "\n",
    "for folder in Simulated_stations_Excel_folders:\n",
    "\n",
    "    DATES_simulated, FLOWS_simulated = read_simulations_excel(folder, Stations_namesLocations)\n",
    "\n",
    "    DATES_SIMULATED.append(DATES_simulated[0])\n",
    "    OUTPUTS_SIMULATED.append(FLOWS_simulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSD_allStn, NRMSD_allStn, KGE_allStn, bias_allStn, corr_allStn, NS_allStn = [],[],[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "import hydroStats as hydroStats\n",
    "for i in range(len(Stations_namesLocations)):\n",
    "\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(y=FLOWS_observed[i],\n",
    "                             x=DATES_observed[i],\n",
    "                    mode='lines',\n",
    "                    name=titles[0],\n",
    "                            opacity=1, \n",
    "                            line=dict(width=1, color='#FFFFFF'))) #,\n",
    "                            #marker = dict(size=2)))\n",
    "    \n",
    "    \n",
    "    Excel_timeseries_observations = pd.DataFrame({'Observed dates':DATES_observed[i], 'Observed flows':FLOWS_observed[i]})\n",
    "    with pd.ExcelWriter(Stations_namesLocations[i][0]+'.xlsx') as writer:  \n",
    "        Excel_timeseries_observations.to_excel(writer, sheet_name='Observations', index=False)\n",
    "                                                 \n",
    "                                    \n",
    "    RMSD, NRMSD, KGE, bias, corr, NS = [],[],[],[],[],[]\n",
    "\n",
    "    Excel_timeseries_simulations = pd.DataFrame({'Simulated dates':DATES_SIMULATED[0]})\n",
    "\n",
    "    for sim in range(len(Simulated_output_paths)+len(Simulated_stations_Excel_folders)):\n",
    "\n",
    "        fig.add_trace(go.Scatter(y=OUTPUTS_SIMULATED[sim][i],\n",
    "                                 x=DATES_SIMULATED[sim],\n",
    "                        mode='lines',\n",
    "                        name=titles[sim+1],\n",
    "                                line=dict(width=1))) #color='#ff7f0e',\n",
    "\n",
    "        Excel_timeseries_simulations.insert(sim+1, titles[sim+1], OUTPUTS_SIMULATED[sim][i])\n",
    "\n",
    "        FLOWS_simulated = OUTPUTS_SIMULATED[sim] \n",
    "        Dates_simulated = DATES_SIMULATED[sim]\n",
    "\n",
    "        max_simulated = max(FLOWS_simulated[i])\n",
    "\n",
    "        start = 0\n",
    "        for d in range(len(DATES_observed[i])):\n",
    "            # Find the match of the first observation to the first simulated day\n",
    "            if DATES_observed[i][d] == Dates_simulated[0]:\n",
    "                start = d\n",
    "                break\n",
    "        startSim = 0\n",
    "        if start == 0:\n",
    "            #Simulation begins before observations\n",
    "            #Find first simulation date\n",
    "            for d in range(len(Dates_simulated)):\n",
    "                if Dates_simulated[d] == DATES_observed[i][0]:\n",
    "                    startSim = d\n",
    "                    break\n",
    "\n",
    "        if startSim == 0 and start ==0 and Dates_simulated[0] != DATES_observed[i][0]: #DATES_observed[i][-1]\n",
    "            #print('There is no overlap of simulation and observation.')\n",
    "            KGE.append('-')\n",
    "            bias.append('-')\n",
    "            corr.append('-')\n",
    "            NS.append('-')\n",
    "            RMSD.append('-')\n",
    "            NRMSD.append('-')\n",
    "            \n",
    "        else:\n",
    "            oval=[]\n",
    "            o = FLOWS_observed[i][start:]\n",
    "            s = []\n",
    "\n",
    "            end = 0\n",
    "            for d in range(len(o)):\n",
    "                if not np.isnan(o[d]): \n",
    "                    try:\n",
    "                        if FLOWS_simulated[i][d+startSim] > 0:\n",
    "                            s.append(FLOWS_simulated[i][d+startSim])\n",
    "                            oval.append(o[d])\n",
    "                    except: \n",
    "                        end = d\n",
    "                        break  \n",
    "\n",
    "            sval = np.asarray(s)\n",
    "\n",
    "            MSE = 0\n",
    "            for d in range(len(oval)):\n",
    "                MSE += (oval[d]-sval[d])**2\n",
    "\n",
    "            if len(oval) > 0:\n",
    "                rmsd = (MSE/len(oval)) ** .5\n",
    "            \n",
    "                RMSD.append(\"{:.2f}\".format(rmsd))\n",
    "                NRMSD.append(\"{:.2f}\".format(rmsd/np.mean(oval)))\n",
    "                KGE.append(\"{0:.2f}\".format(hydroStats.KGE(s=sval, o=oval, warmup=0)))\n",
    "                bias.append(\"{0:.2f}\".format(hydroStats.pc_bias2(s=sval, o=oval, warmup=0)))\n",
    "                corr.append(\"{0:.2f}\".format(hydroStats.correlation(s=sval, o=oval, warmup=0)))\n",
    "                NS.append(\"{0:.2f}\".format(hydroStats.NS(s=sval, o=oval, warmup=0)))\n",
    "            else:\n",
    "                RMSD.append('-')\n",
    "                NRMSD.append('-')\n",
    "                KGE.append('-')\n",
    "                bias.append('-')\n",
    "                corr.append('-')\n",
    "                NS.append('-')\n",
    "                \n",
    "    with pd.ExcelWriter(Stations_namesLocations[i][0]+'.xlsx',\n",
    "                mode='a', engine=\"openpyxl\") as writer:  \n",
    "        Excel_timeseries_simulations.to_excel(writer, sheet_name='Simulations', index=False)\n",
    "\n",
    "    data_WB = {'KGE': KGE, 'NS':NS, 'Bias':bias, 'Corr':corr, 'RMSD':RMSD, 'NRMSD':NRMSD}\n",
    "    df = pd.DataFrame(data_WB)\n",
    "    df=df.style.set_table_styles([{'selector': 'th', 'props': [('font-size', '12pt')]}]).set_properties(**{\"font-size\": \"12pt\"}).hide(axis='index') \n",
    "    \n",
    "    #\"\"\"\n",
    "    fig.update_layout(title=output_variable +': '+ Stations_namesLocations[i][0],\n",
    "                   yaxis_title=output_variable, template=template)\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "    print(Stations_namesLocations[i][0])\n",
    "\n",
    "    \n",
    "    \n",
    "    display(df)\n",
    "    \n",
    "    RMSD_allStn.append(RMSD) \n",
    "    NRMSD_allStn.append(NRMSD)\n",
    "    KGE_allStn.append(KGE)\n",
    "    bias_allStn.append(bias)\n",
    "    corr_allStn.append(corr)\n",
    "    NS_allStn.append(NS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "z= [stn for stn in KGE_allStn]\n",
    "\n",
    "fig = px.imshow(z, template=template, text_auto=True, zmin = -2, zmax = 1.0, title='Kling-Gupta efficiency',\n",
    "                labels=dict(y=\"Station\", x='Run', color=\"Rating\"),\n",
    "                #x=titles[1:],\n",
    "                y=[i[0] for i in Stations_namesLocations])\n",
    "fig.show()\n",
    "\n",
    "z= [stn for stn in KGE_allStn]\n",
    "fig = px.imshow(z, template=template, text_auto=True, zmin = -2, zmax = 1.0, title='Kling-Gupta efficiency',\n",
    "                labels=dict(y=\"Station\", x='Run', color=\"Rating\"),\n",
    "                x=[i for i in range(len(Simulation_output_folders)+len(Simulated_stations_Excel_folders))],\n",
    "                y=[i[0] for i in Stations_namesLocations])\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "z= [stn for stn in NS_allStn]\n",
    "fig = px.imshow(z, template=template, text_auto=True, zmin = -2, zmax = 1.0, title='Nash-Sutcliffe efficiency',\n",
    "                labels=dict(y=\"Station\", x='Run', color=\"Rating\"),\n",
    "                x=[i for i in range(len(Simulation_output_folders)+len(Simulated_stations_Excel_folders))],\n",
    "                y=[i[0] for i in Stations_namesLocations])\n",
    "fig.show()\n",
    "\n",
    "z= [stn for stn in corr_allStn]\n",
    "fig = px.imshow(z, template=template, text_auto=True, zmin = 0, zmax = 1.0, title='Correlation',\n",
    "                labels=dict(y=\"Station\", x='Run', color=\"Rating\"),\n",
    "                x=[i for i in range(len(Simulation_output_folders)+len(Simulated_stations_Excel_folders))],\n",
    "                y=[i[0] for i in Stations_namesLocations])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
